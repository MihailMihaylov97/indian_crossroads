{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Environments.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch  \n",
    "import numpy as np  \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from Environments import Square_Crossroads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_times_steps = 3\n",
    "# seed = 10\n",
    "# dist_cars = 0.5\n",
    "\n",
    "# env = Square_Crossroads(seed, dist_cars)\n",
    "# env.reset()\n",
    "\n",
    "# action_space = {0:[0,0], 1:[0,0], 2:[0,0], 3:[0,0]}\n",
    "# total_reward = 0\n",
    "\n",
    "# print(env.states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_tensor = torch.zeros([4,2], dtype=torch.float32)\n",
    "# action_tensor = torch.zeros([4,2], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor_Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size_actor, hidden_size_critic):\n",
    "        super(Actor_Critic, self).__init__()\n",
    "      \n",
    "        self.num_inputs = num_inputs\n",
    "        \n",
    "        \n",
    "        self.critic_linear1 = nn.Linear(self.num_inputs, hidden_size_critic)\n",
    "        self.critic_linear2 = nn.Linear(hidden_size_critic, 1)\n",
    "        \n",
    "        self.actor_linear1 = nn.Linear(self.num_inputs, hidden_size_actor)\n",
    "        self.actor_linear2 = nn.Linear(hidden_size_actor, hidden_size_actor)\n",
    "        self.alpha = nn.Linear(hidden_size_actor, 1)\n",
    "        self.beta = nn.Linear(hidden_size_actor, 1)\n",
    "        \n",
    "        self.pos_neg_1 = nn.Linear(self.num_inputs, 10)\n",
    "        self.pos_neg_2 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, state_tensor):\n",
    "#         print(state_tensor)\n",
    "        state_tensor = Variable(state_tensor.float())\n",
    "#         print(state_tensor)\n",
    "        value = F.relu(self.critic_linear1(state_tensor))\n",
    "        value = self.critic_linear2(value)\n",
    "        \n",
    "        policy_dist = F.relu(self.actor_linear1(state_tensor))\n",
    "        policy_dist = F.relu(self.actor_linear2(policy_dist))\n",
    "\n",
    "        policy_dist_alpha = torch.clamp(self.alpha(policy_dist), 1.9, 2.2)\n",
    "        policy_dist_beta = torch.clamp(self.beta(policy_dist), 1.9, 2.2)\n",
    "        \n",
    "        sign = F.relu(self.pos_neg_1(state_tensor))\n",
    "        sign = F.softmax(self.pos_neg_2(sign))\n",
    "        \n",
    "        return value, policy_dist_alpha, policy_dist_beta, sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
