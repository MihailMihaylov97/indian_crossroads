{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square_Crossroads():\n",
    "    \n",
    "    def __init__(self, n_time_steps, seed, dist_cars):\n",
    "        \n",
    "        # n_time_steps, length and width are not used yet, but will probably be used later\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.length = 10\n",
    "        self.width = 10\n",
    "        \n",
    "        \n",
    "        self.dist_cars = dist_cars\n",
    "        \n",
    "        # initial 4 cars\n",
    "        self.cars = np.array([0, 1, 2, 3])\n",
    "        \n",
    "        # create 4 entrances\n",
    "        self.state_a = [0, 5]\n",
    "        self.state_b = [5, 0]\n",
    "        self.state_c = [5, 10]\n",
    "        self.state_d = [10, 5]\n",
    "        self.exits = [self.state_a, self.state_b, self.state_c, self.state_d]\n",
    "\n",
    "        self.set_seed(seed)\n",
    "        self.reset()\n",
    "                    \n",
    "        \n",
    "    def step(self, action_space):\n",
    "        \n",
    "        # not done yet\n",
    "        # crash reward \n",
    "        # static reward (if velocity = 0, -5?)\n",
    "        # timestamp reward (-1)\n",
    "        \n",
    "        # calculate the exact place we will get to using curvature = action_space[0] and acceleration = action_space[1]\n",
    "        \n",
    "        print(f\"Taking a step in the environment with these actions: \\n curvature = {action_space[0]}, acceleration = {action_space[1]}\")\n",
    "        \n",
    "        done = False\n",
    "        reward = 0\n",
    "        time_reward = -1\n",
    "        static_reward = 0\n",
    "        reward_crash = 0\n",
    "        reward_success = 0\n",
    "        \n",
    "        # Take a step\n",
    "        \n",
    "        \n",
    "        # calculate crash reward\n",
    "        reward_crash = self.check_crash(self.dist_cars)\n",
    "        \n",
    "        reward_success = self.check_success()\n",
    "\n",
    "        reward_static = self.check_static()\n",
    "        \n",
    "        reward = reward_crash + static_reward + time_reward + reward_success\n",
    "        return self.states, reward, done\n",
    "    \n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    def new_car(self):\n",
    "        # add a new car\n",
    "        \n",
    "        last_car = self.cars[-1]\n",
    "        new_car = last_car + 1\n",
    "        \n",
    "        # add new car index to list of all cars\n",
    "        self.cars = np.append(self.cars, new_car)\n",
    "        \n",
    "        # take a random spawn exit\n",
    "        spawn = np.random.choice(len(self.exits))\n",
    "        \n",
    "        # remove the spawn exit from the target exits\n",
    "        target_indexes = list(np.arange(len(self.exits)))\n",
    "        target_indexes.pop(spawn)\n",
    "        \n",
    "        \n",
    "        # choose a random target exit (spawn exit is already excluded)\n",
    "        rand_target = np.random.choice(target_indexes)\n",
    "        \n",
    "        # added the new car with next_index : [spawn exit, target exit]\n",
    "        self.states[new_car] = [self.exits[spawn], self.exits[rand_target], 0, 0]\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        # reset the whole environment\n",
    "        \n",
    "        print(\"Environment reset with param\")\n",
    "        \n",
    "        self.states = dict.fromkeys(self.cars)\n",
    "        \n",
    "        for car in self.states:\n",
    "            \n",
    "            # remove the spawn exit from the target exits\n",
    "            target_indexes = list(np.arange(len(self.exits)))\n",
    "            target_indexes.pop(car)\n",
    "            \n",
    "            # choose a random target exit (spawn exit is already excluded)\n",
    "            rand_target = np.random.choice(target_indexes)\n",
    "            \n",
    "            # create a dictionary of car : [spawn exit, target exit, velocity, curvature]\n",
    "            self.states[car] = [self.exits[car], self.exits[rand_target], 0, 0]\n",
    "    \n",
    "    \n",
    "    def check_crash(self, dist_cars):\n",
    "        # check if a crash has occured and decrease the reward by 20 for every crash\n",
    "        \n",
    "        reward_crash = 0\n",
    "        \n",
    "        all_points = [a[0] for a in self.states.values()]\n",
    "        \n",
    "        for p0, p1 in itertools.combinations(all_points, 2):\n",
    "            \n",
    "            tmp_dist = distance(p0, p1)\n",
    "            \n",
    "            if tmp_dist <= dist_cars: reward_crash -=20\n",
    "                \n",
    "        return reward_crash\n",
    "                \n",
    "    def check_success(self):\n",
    "        # check if a car has successfully exited and increase reward by 100 for each success\n",
    "        \n",
    "        reward_success = 0\n",
    "        \n",
    "        # list of cars that should successfully be removed\n",
    "        exit = []\n",
    "        \n",
    "        for car, car_prop in self.states.items():\n",
    "            print(self.states[car])\n",
    "            if self.states[car][0] == self.states[car][1]:\n",
    "                \n",
    "                exit.append(car)          \n",
    "                reward_success += 100\n",
    "                \n",
    "        for c in exit:\n",
    "            del self.states[c]\n",
    "            \n",
    "        return reward_success\n",
    "        \n",
    "    def check_static(self):\n",
    "        # check if velocity is 0 and decrease the reward by 10 for each car with velocity 0\n",
    "        \n",
    "        reward_static = 0\n",
    "        \n",
    "        for car_prop in self.states.values():\n",
    "            \n",
    "            if car_prop[2] == 0:\n",
    "                reward_static += -10\n",
    "                \n",
    "        return reward_static\n",
    "    \n",
    "def distance(p0, p1):\n",
    "    # calculates the distance between 2 points\n",
    "    return math.sqrt((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment reset with param\n",
      "{0: [[0, 5], [5, 10], 0, 0], 1: [[5, 0], [5, 10], 0, 0], 2: [[5, 10], [0, 5], 0, 0], 3: [[10, 5], [0, 5], 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "n_times_steps = 3\n",
    "seed = 10\n",
    "dist_cars = 0.5\n",
    "\n",
    "env = Square_Crossroads(n_times_steps, seed, dist_cars)\n",
    "\n",
    "print(env.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a step in the environment with these actions: \n",
      " curvature = 0.6580896861316505, acceleration = 12.638227179424018\n",
      "[[0, 5], [5, 10], 0, 0]\n",
      "[[5, 0], [5, 10], 0, 0]\n",
      "[[5, 10], [0, 5], 0, 0]\n",
      "[[10, 5], [0, 5], 0, 0]\n"
     ]
    }
   ],
   "source": [
    "curvature = np.random.uniform(-2, 4)\n",
    "acceleration = np.random.uniform(-4, 16)\n",
    "\n",
    "action_space = (curvature, acceleration)\n",
    "states, reward, done = env.step(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[0, 5], [5, 10], 0, 0],\n",
       " 1: [[5, 0], [5, 10], 0, 0],\n",
       " 2: [[5, 10], [0, 5], 0, 0],\n",
       " 3: [[10, 5], [0, 5], 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[0, 5], [5, 10], 0, 0], 1: [[5, 0], [5, 10], 0, 0], 2: [[5, 10], [0, 5], 0, 0], 3: [[10, 5], [0, 5], 0, 0], 4: [[5, 0], [0, 5], 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "env.new_car()\n",
    "print(env.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bit88b32d29ff2048dd80b2200dd1cd051b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
